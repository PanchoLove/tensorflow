{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import sys\n",
    "from tkinter import *\n",
    "import tkinter.filedialog as fdialog\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "# Note: Model used for SSDLite_Mobilenet_v2\n",
    "#PATH_TO_CKPT = './object_detection/ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb'\n",
    "PATH_TO_CKPT = './object_detection/faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = './object_detection/data/mscoco_label_map.pbtxt'\n",
    "\n",
    "NUM_CLASSES = 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "#print(categories)\n",
    "#print(category_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nonblack_np(img):\n",
    "    \"\"\"Return the number of pixels in img that are not black.\n",
    "    img must be a Numpy array with colour values along the last axis.\n",
    "\n",
    "    \"\"\"\n",
    "    return img.any(axis=-1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_team(image, col1, col2, col_gk, show = False):\n",
    "    # convert to HSV colorbase\n",
    "    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # define color intervals (in HSV colorbase)\n",
    "    lower_yellow = np.array([25,100,100])\n",
    "    upper_yellow = np.array([35,255,255])\n",
    "    lower_lightblue = np.array([95,80,80])\n",
    "    upper_lightblue = np.array([120,170,255])\n",
    "    lower_blue = np.array([100,80,80])\n",
    "    upper_blue = np.array([120,255,255])\n",
    "    lower_red = np.array([165,50,100])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    #lower_red2 = np.array([0,50,100])\n",
    "    #upper_red2 = np.array([10,255,255])\n",
    "    lower_purple = np.array([130,80,80])\n",
    "    upper_purple = np.array([160,255,255])\n",
    "    lower_green = np.array([35,80,80])\n",
    "    upper_green = np.array([50,255,255])\n",
    "    lower_orange = np.array([28,80,80])\n",
    "    upper_orange = np.array([30,255,255])\n",
    "    lower_white = np.array([0,0,240])\n",
    "    upper_white = np.array([190,60,255])\n",
    "    \n",
    "    # define the list of boundaries\n",
    "    # Team 1\n",
    "    if col1 == 'red':\n",
    "        rgb1_low = lower_red\n",
    "        rgb1_up = upper_red\n",
    "    elif col1 == 'lightblue':\n",
    "        rgb1_low = lower_lightblue\n",
    "        rgb1_up = upper_lightblue\n",
    "    elif col1 == 'yellow':\n",
    "        rgb1_low = lower_yellow\n",
    "        rgb1_up = upper_yellow\n",
    "    elif col1 == 'blue':\n",
    "        rgb1_low = lower_blue\n",
    "        rgb1_up = upper_blue\n",
    "    elif col1 == 'purple':\n",
    "        rgb1_low = lower_purple\n",
    "        rgb1_up = upper_purple\n",
    "    elif col1 == 'green':\n",
    "        rgb1_low = lower_green\n",
    "        rgb1_up = upper_green\n",
    "    elif col1 == 'orange':\n",
    "        rgb1_low = lower_orange\n",
    "        rgb1_up = upper_orange\n",
    "    elif col1 == 'white':\n",
    "        rgb1_low = lower_white\n",
    "        rgb1_up = upper_white\n",
    "    # Team 2\n",
    "    if col2 == 'red':\n",
    "        rgb2_low = lower_red\n",
    "        rgb2_up = upper_red\n",
    "    elif col2 == 'lightblue':\n",
    "        rgb2_low = lower_lightblue\n",
    "        rgb2_up = upper_lightblue\n",
    "    elif col2 == 'yellow':\n",
    "        rgb2_low = lower_yellow\n",
    "        rgb2_up = upper_yellow\n",
    "    elif col2 == 'blue':\n",
    "        rgb2_low = lower_blue\n",
    "        rgb2_up = upper_blue\n",
    "    elif col2 == 'purple':\n",
    "        rgb2_low = lower_purple\n",
    "        rgb2_up = upper_purple\n",
    "    elif col2 == 'green':\n",
    "        rgb2_low = lower_green\n",
    "        rgb2_up = upper_green\n",
    "    elif col2 == 'orange':\n",
    "        rgb2_low = lower_orange\n",
    "        rgb2_up = upper_orange\n",
    "    elif col2 == 'white':\n",
    "        rgb2_low = lower_white\n",
    "        rgb2_up = upper_white\n",
    "    # Goal-keeper\n",
    "    if col_gk == 'red':\n",
    "        rgbGK_low = lower_red\n",
    "        rgbGK_up = upper_red\n",
    "    elif col_gk == 'lightblue':\n",
    "        rgbGK_low = lower_lightblue\n",
    "        rgbGK_up = upper_lightblue\n",
    "    elif col_gk == 'yellow':\n",
    "        rgbGK_low = lower_yellow\n",
    "        rgbGK_up = upper_yellow\n",
    "    elif col_gk == 'blue':\n",
    "        rgbGK_low = lower_blue\n",
    "        rgbGK_up = upper_blue\n",
    "    elif col_gk == 'purple':\n",
    "        rgbGK_low = lower_purple\n",
    "        rgbGK_up = upper_purple\n",
    "    elif col_gk == 'green':\n",
    "        rgbGK_low = lower_green\n",
    "        rgbGK_up = upper_green\n",
    "    elif col_gk == 'orange':\n",
    "        rgbGK_low = lower_orange\n",
    "        rgbGK_up = upper_orange\n",
    "    elif col_gk == 'white':\n",
    "        rgbGK_low = lower_white\n",
    "        rgbGK_up = upper_white\n",
    "\n",
    "    boundaries = [\n",
    "    (rgb1_low, rgb1_up), #red\n",
    "    (rgb2_low, rgb2_up), #light-blue\n",
    "    (rgbGK_low, rgbGK_up)\n",
    "    ]\n",
    "    # ([25, 146, 190], [96, 174, 250]) #yellow\n",
    "    i = 0\n",
    "    for (lower, upper) in boundaries:\n",
    "        # create NumPy arrays from the boundaries\n",
    "        lower = np.array(lower, dtype = \"uint8\")\n",
    "        upper = np.array(upper, dtype = \"uint8\")\n",
    "\n",
    "        # find the colors within the specified boundaries and apply\n",
    "        # the mask\n",
    "        mask = cv2.inRange(img_hsv, lower, upper)\n",
    "        output = cv2.bitwise_and(image, image, mask = mask)\n",
    "        tot_pix = count_nonblack_np(image)\n",
    "        color_pix = count_nonblack_np(output)\n",
    "        ratio = color_pix/tot_pix\n",
    "#         print(\"ratio is:\", ratio)\n",
    "        if ratio > 0.01 and i == 0:\n",
    "            return 'Team1' #'red'\n",
    "        elif ratio > 0.01 and i == 1:\n",
    "            return 'Team2' #'yellow'\n",
    "        elif ratio > 0.01 and i == 2:\n",
    "            return 'GK'\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "        if show == True:\n",
    "            cv2.imshow(\"images\", np.hstack([image, output]))\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "              cv2.destroyAllWindows() \n",
    "    return 'not_sure'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To View Color Mask\n",
    "# filename = 'frame74.jpg' #'image2.jpg'\n",
    "# image = cv2.imread(filename)\n",
    "# resize = cv2.resize(image, (640,360))\n",
    "# detect_team(resize, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1493e47d395f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfdialog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maskopenfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitialdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Select file\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiletypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avi files\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"*.avi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all files\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"*.*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example picture: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mexample_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpathAux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_image_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# Para abrir ventana elegir archivo de video\n",
    "root = Tk()\n",
    "root.filename =  fdialog.askopenfile(initialdir = \"/\",title = \"Select file\",filetypes = ((\"avi files\",\"*.avi\"),(\"all files\",\"*.*\")))\n",
    "print('Example picture: ', root.filename.name)\n",
    "example_image_path = root.filename.name\n",
    "pathAux = example_image_path.find('/',-20)\n",
    "example_image = example_image_path[pathAux+1:]\n",
    "print(example_image)\n",
    "root.destroy()\n",
    "\n",
    "color_1 = str(input('Color team 1 (red,yellow,blue,lightblue,green,white,etc) : ')) \n",
    "color_2 = str(input('Color team 2: ')) \n",
    "color_gk = str(input('Color Goalkeeper: ')) \n",
    "name_team1 = str(input('Name team 1: ')) \n",
    "name_team2 = str(input('Name team 2: ')) \n",
    "\n",
    "#intializing the web camera device\n",
    "\n",
    "#filename = 'DORSALES/D13.avi' #'soccer_small.mp4'\n",
    "filename = example_image\n",
    "cap = cv2.VideoCapture(filename)\n",
    "size = (int(cap.get(3)),\n",
    "        int(cap.get(4)))\n",
    "\n",
    "out = cv2.VideoWriter()\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "success = out.open('soccer_out.avi',fourcc,20.0,size,True)\n",
    "\n",
    "# Running the tensorflow session\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "   counter = 0\n",
    "   while (True):\n",
    "      ret, image_np = cap.read()\n",
    "      counter += 1\n",
    "      if ret:\n",
    "          h = image_np.shape[0]\n",
    "          w = image_np.shape[1]\n",
    "\n",
    "      if not ret:\n",
    "        break\n",
    "      if counter % 1 == 0:\n",
    "          # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "          image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "          image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "          # Each box represents a part of the image where a particular object was detected.\n",
    "          boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "          # Each score represent how level of confidence for each of the objects.\n",
    "          # Score is shown on the result image, together with the class label.\n",
    "          scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "          classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "          num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "          # Actual detection.\n",
    "          (boxes, scores, classes, num_detections) = sess.run(\n",
    "              [boxes, scores, classes, num_detections],\n",
    "              feed_dict={image_tensor: image_np_expanded})\n",
    "          # Visualization of the results of a detection.\n",
    "          vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              np.squeeze(boxes),\n",
    "              np.squeeze(classes).astype(np.int32),\n",
    "              np.squeeze(scores),\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=3,\n",
    "              min_score_thresh=0.6)\n",
    "        \n",
    "          frame_number = counter\n",
    "          loc = {}\n",
    "          for n in range(len(scores[0])):\n",
    "             if scores[0][n] > 0.60:\n",
    "                # Calculate position\n",
    "                ymin = int(boxes[0][n][0] * h)\n",
    "                xmin = int(boxes[0][n][1] * w)\n",
    "                ymax = int(boxes[0][n][2] * h)\n",
    "                xmax = int(boxes[0][n][3] * w)\n",
    "\n",
    "                # Find label corresponding to that class\n",
    "                for cat in categories:\n",
    "                    if cat['id'] == classes[0][n]:\n",
    "                        label = cat['name']\n",
    "\n",
    "                ## extract every person\n",
    "                if label == 'person':\n",
    "                    #crop them\n",
    "                    crop_img = image_np[ymin:ymax, xmin:xmax]\n",
    "                    color = detect_team(crop_img,color_1,color_2,color_gk)\n",
    "                    if color != 'not_sure':\n",
    "                        coords = (xmin, ymin)\n",
    "                        if color == 'Team1':\n",
    "                            loc[coords] = name_team1\n",
    "                        elif color == 'Team2':\n",
    "                            loc[coords] = name_team2\n",
    "                        elif color == 'GK':\n",
    "                            loc[coords] = 'GK'\n",
    "                        else:\n",
    "                            loc[coords] = name_team2\n",
    "                        \n",
    "        ## print color next to the person\n",
    "          for key in loc.keys():\n",
    "            text_pos = str(loc[key])\n",
    "            cv2.putText(image_np, text_pos, (key[0], key[1]-20), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 0, 0), 2) # Text in black\n",
    "      \n",
    "      print(counter) #cv2.imshow('image', image_np)\n",
    "      out.write(image_np)\n",
    "       \n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "          break\n",
    "\n",
    "print('Done!')\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
